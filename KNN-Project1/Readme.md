# KNN-Numerical-Classification

This project explores the application of the K-Nearest Neighbors (KNN) algorithm for classifying data points based on numerical features. The dataset used in this project is intentionally unlabeled to highlight KNN's ability to work without domain knowledge.

## Key Highlights

- **Feature Scaling:** Demonstrates the importance of standardizing features to ensure fair comparison and optimal model performance.
- **Hyperparameter Tuning:** Explores the impact of different 'K' values (number of neighbors) on classification accuracy.
- **Model Evaluation:** Evaluates the KNN model on a test set, achieving an accuracy of 96%.
- **Colab Notebook:** Provides a detailed walkthrough of the implementation and analysis in a Google Colab notebook.

## Usage

1. Clone this repository.
2. Open the `KNN_Numerical_Classification.ipynb` notebook in Google Colab.
3. Run the notebook cells to reproduce the results.

## Dependencies

- pandas
- numpy
- scikit-learn
- matplotlib

Feel free to explore, experiment, and adapt this project to your own data!
